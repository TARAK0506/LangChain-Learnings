{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv # type: ignore\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq # type: ignore\n",
    "\n",
    "LlamaModel = ChatGroq(\n",
    "    model = \"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I'm not familiar with the term \"Krishnaik.\" It's possible that it's a lesser-known or regional term, or it could be a misspelling or variation of a different word.\n",
      "\n",
      "However, I can suggest a few possibilities:\n",
      "\n",
      "* Krishna: Krishna is a major deity in Hinduism, known for his divine wisdom, courage, and benevolence. He is considered the eighth avatar (incarnation) of the god Vishnu and is revered as a symbol of love, compassion, and wisdom.\n",
      "* Krishnaism: Krishnaism is a term used to describe the religious movement or tradition that focuses on the worship and devotion to Lord Krishna. It encompasses various branches of Hinduism, such as Vaishnavism, Gaudiya Vaishnavism, and others, that consider Krishna as the supreme deity.\n",
      "* Krishnaites: I couldn't find any information on \"Krishnaites.\" It's possible that it's a misspelling or a variation of the term \"Krishnaite,\" which could refer to a follower or devotee of Lord Krishna.\n",
      "\n",
      "If you could provide more context or clarify what you mean by \"Krishnaik,\" I'd be happy to try and assist you further.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\",\"You are an helpful Assistant.\"),\n",
    "    (\"human\",\"Tell me about the Krishnaik.\"),\n",
    "]\n",
    "\n",
    "response = LlamaModel.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "# print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader # type: ignore\n",
    "\n",
    "loader = TextLoader(\"data/cpp.txt\")\n",
    "text = loader.load()\n",
    "\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Loader\n",
    "from langchain_community.document_loaders import CSVLoader # type: ignore\n",
    "\n",
    "csv_loader = CSVLoader(\"data/Boston.csv\")\n",
    "csv_data = csv_loader.load()\n",
    "\n",
    "# csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Groq from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have become increasingly important in recent years due to their ability to process and generate human-like language at rapid speeds, enabling various applications and benefits. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Real-time applications**: Fast language models enable real-time language processing, which is essential for applications like chatbots, virtual assistants, and language translation systems. These models can respond quickly to user input, providing a seamless and interactive experience.\n",
      "2. **Efficient processing**: Fast language models can process large amounts of data quickly, making them suitable for applications that require rapid analysis of massive datasets, such as social media monitoring, sentiment analysis, or text summarization.\n",
      "3. **Improved user experience**: Fast language models can reduce latency and response times, leading to a better user experience in applications like language translation, search engines, and content generation.\n",
      "4. **Enhanced productivity**: Fast language models can automate tasks like text generation, language translation, and content creation, freeing up humans to focus on higher-value tasks that require creativity, empathy, and critical thinking.\n",
      "5. **Scalability**: Fast language models can handle large volumes of data and user requests, making them ideal for large-scale applications like customer service chatbots, language translation platforms, or content generation platforms.\n",
      "6. **Competitive advantage**: Organizations that leverage fast language models can gain a competitive advantage by providing faster and more efficient services, improving customer satisfaction, and increasing productivity.\n",
      "7. **Research and development**: Fast language models can accelerate research in natural language processing (NLP) and artificial intelligence (AI), enabling scientists to explore new applications, models, and techniques more quickly.\n",
      "8. **Low-latency edge computing**: Fast language models can be deployed on edge devices, such as smartphones or IoT devices, enabling low-latency language processing and reducing the need for cloud-based processing.\n",
      "9. **Enhanced accessibility**: Fast language models can facilitate communication for people with disabilities, such as those who require real-time language translation or text-to-speech synthesis.\n",
      "10. **Cost savings**: Fast language models can reduce the computational resources required for language processing, leading to cost savings and more efficient use of infrastructure.\n",
      "\n",
      "To achieve fast language models, researchers and developers employ various techniques, including:\n",
      "\n",
      "1. **Model pruning**: Reducing the size and complexity of language models to improve inference speed.\n",
      "2. **Quantization**: Representing model weights and activations using fewer bits to reduce computation and memory requirements.\n",
      "3. **Knowledge distillation**: Training smaller models (students) to mimic the behavior of larger, pre-trained models (teachers).\n",
      "4. **Parallelization**: Distributing language model computations across multiple processing units, such as GPUs or TPUs.\n",
      "5. **Specialized hardware**: Designing custom hardware accelerators, like TPUs or ASICs, optimized for language model computations.\n",
      "\n",
      "By leveraging these techniques, fast language models can unlock various applications and benefits, transforming the way humans interact with machines and each other.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI # type: ignore\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key=os.environ['GROQ_API_KEY']\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "model=\"llama3-70b-8192\",\n",
    "messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models.\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
